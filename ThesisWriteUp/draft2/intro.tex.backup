%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Introduction}
\label{ch:Introduction}

\begin{epigraph}
\end{epigraph}

\section{Research Motivation}
\label{sec:Research Motivation}

In mineral exploration there are many forms of information that can be used to determine the location of an economic deposit. These can be divided broadly into geological and geophysical data. Geological data refers to the study of the rocks in a region through surface samples, bore holes, and an understanding of how rock units interrelate under the surface. Geophysical data refers to recovered measurements of some field that is related to the physical properties of the rocks that will aid in the understanding of the deposit. For exploration to be as effective as possible, we need to find ways of integrating the geological and geophysical information that produce exploration vectors to the target. One of the major tools in using geophysical data to create geologically significant interpretations is inversion.

The overarching goal of geophysical inversion is to recover distributions of physical properties in the ground to aid in mineral exploration. To be useful to this end the spacial distribution of the physical property (the geophysical model) needs to both fit the geophysical data and match existing geological interpretations. 

Since geophysical inversions are by their nature non-unique (because of data uncertainty and there typically being many more model parameters than data), \emph{a priori} information needs to be added to provide a model that matches the geology of a deposit. Much work has been done to create a mathematical framework to allow the inclusion of geological and petrophysical information into geophysical inversions (for example \cite{li19963}). However, an area where more work must be done is the creation of tools to take the petrophysical and geological data in the forms that are generally provided and create usable constraints that can be applied to inversions.

The research in this thesis will attempt to do exactly that: provide new tools in an integrated framework that will allow the incorporation of \emph{a priori} information into geophysical inversions. The inclusion of \emph{a priori} information in inversions is not novel. Many researchers, especially at the \ac{GIF}, before me have used the mathematical framework to add geological and petrophysical information to inversions (for example \citealt{Lelievre2009Integrating},\citealt{phillips2001thesis}, \citealt{farquharson2008geologically}). 

In addition, \cite{williams2008geologically} develops a software package to create constraints for inversions from a wide array of data types. What is lacking in the previous research is the link between the creation of inversion constraints with the processing of data and the running of inversions. By integrating the tools I create in this thesis into the framework of GIFtools and Model Builder I attempt to provide this link. 

GIFtools and Model Builder are a suite of tools who's origins date back to \cite{williams2008geologically}, but which have been sufficiently updated that they deserve further treatment. The goal now, as in \cite{williams2008geologically}, is to create a set of \ac{GUI} tools that make the running of \ac{GIF} inversion codes simple and easy. 

GIFtools was a set of \ac{GUI} tools that made the running \ac{GIF} inversion codes (and managing the may files and parameters they require) more straight-forward. GIFtools has evolved into a software environment that allows the running of advanced inversion. It maintains the original purpose of helping run \ac{GIF} inversion codes, and has incorporated many inversion codes that were not originally supported by the older GIFtools environment. It also now includes significant data visualization and quality control, mesh creation (in both 2D and 3D tensor meshes as well as 3D ocTree meshes), and model visualization and editing functionality.

Model Builder, first described and implemented in \cite{williams2008geologically}, is a set of \ac{GUI} tools that facilitate the creation of constraints from geological and petrophysical data for \ac{GIF} inversion codes. It largely consisted of a work flow for the incorporation of said data into reference models, bounds, and weights that could be used in \ac{GIF} inversion codes. 

While the tools created in \cite{williams2008geologically} were very powerful, the interface was not always straightforward to use. This was largely due to the interface's lack of flexibility. Each part of the process occurred in a strict order, meaning that if the user made an error the whole process had to be restarted. In addition the program lacked visualization support and the ability to do quality control on the geological and petrophysical data that was to be incorporated.

By integrating these two sets of tools into one, I make the incorporation of \emph{a priori} information into inversions much more expedient, thus encouraging greater uptake by industry.  GIFtools and Model Builder allow users do quality control on data, create constraints, and run inversions within the same software framework. The interface by which \emph{a priori} information can be incorporated has been much updated from \cite{williams2008geologically}, and tools to incorporate new forms of data into inversions have been added. 

The interfaces that aid data and model viewing, quality control, and the creation of constraints is not merely a convenience. At the current level of inversion techniques, each step in the process of recovering an inversion result depends greatly on the expertise and interpretation of a geophysicist user. Without the tools to view, compare, edit, and create, these users are not able to fully exploit the information provided by geophysical data and inversion to the field of mineral exploration and other applications.



\section{Regularized Inversion}
\label{sec:Regularized Inversion}

In the general case, geophysical inversion involves the solving of a system that is defined by some forward operator that maps from a given model to predicted data,
\begin{equation}
\mathbf d = \mathbb F [\mathbf m],\label{eq:forwardProb}
\end{equation}
where $\mathbf d \in \mathbb R^N$ is the geophysical data ($N$ is the number of data collected),  $\mathbf m \in \mathbb R^M$ is the discretized model that describes the distribution of some physical property in the ground ($M$ is the number cells in the earth model), and $\mathbb F$ is the forward operator that mediates between them. In the context of this thesis, $\mathbf d$ is either magnetic or gravity data measured with a ground or aerial survey, $\mathbf m$ is either a magnetic susceptibility or density model, and $\mathbb F$ is the magnetic or gravitational forward operator which has the convenient property of being linear. Since we are interested in recovering the model $\mathbf m$, we are interested in finding the inverse of $\mathbb F$,
\begin{equation}
\mathbf m= \mathbb F^{-1}\mathbf d. \label{eq:inverseProb}
\end{equation}
Unfortunately the inversion of $\mathbb F$ is far from trivial as the problem is ill-posed. Firstly since there are usually more model parameters than data ($M > N$) there are an infinite number of possible distributions of the physical property that will predict the same observed data. Secondly the system is unstable; that is, a small amount of error in the measurements can lead to large changes in the recovered model. To recover a model despite these difficulties, the problem is regularized by adding \emph{a prioi} information in the form of a \ac{MOF} or regularization functional. Once the problem is regularized, it is solved by minimizing the objective function,
\begin{equation}
\phi(\mathbf m) = \phi_d + \beta \phi_m
\end{equation}
\label{eq:objectiveFunc}
where $\phi$ is the objective function, $\phi_d$ and $\phi_m$ are the data and model objective functions respectively, and $\beta$ is a trade-off parameter that scales between them. $\phi_d$ is defined as a least squares (or $L_2$) formulation,
\begin{equation}
\phi_d =\|\mathbf W_d\Big(\mathbb F [\mathbf m] - \mathbf d^{obs}\Big)\|^2\\
\end{equation}
\label{eq:phid}
\begin{equation}
 \mathbf d^{obs} = \mathbb F[\mathbf m^{true}] + \mathbf e
\end{equation}
\label{eq:dobs}
where $\mathbf d^{obs}$ is the observed data, that is the true data contaminated with noise $\mathbf e$, and $\mathbf W_d$ is the data weighting matrix with the diagonal entries equal to the reciprocal of each datum's standard deviation,
\begin{equation}
\mathbf W_d = \begin{bmatrix}
       \frac{1}{\sigma_1}  & 0 & \cdots & 0   \\
       0 &  \frac{1}{\sigma_2}  & 0 &  \vdots \\
       \vdots & & \ddots & 0\\
       0  & \cdots & 0 & \frac{1}{\sigma_N}
     \end{bmatrix},
\end{equation}
\label{eq:wd}
where each $\sigma_i$ is that datum's assigned standard deviation. Meanwhile $\phi_m$ is can take many forms. In \cite{li19963} it is defined in the continuous formulation as,
\begin{align}
\phi_m =&\alpha_s \|\mathbf w_s \big[(\mathbf m - \mathbf m_{ref})\big]\|^2 + \dots\label{eq:phim}\\ 
&\alpha_x \|\mathbf w_x \mathbf G_x \big[(\mathbf m -\mathbf  m_{ref})\big]\|^2 + \dots\notag\\ 
&\alpha_y \|\mathbf w_y \mathbf G_y \big[(\mathbf m - \mathbf m_{ref})\big]\|^2 + \dots\notag\\ 
&\alpha_z \|\mathbf w_z  \mathbf G_z  \big[(\mathbf m - \mathbf m_{ref})\big]\|^2\notag.
\end{align}
The first term in \autoref{eq:phim} promotes smallness; that is, the model must be close in value to the reference model $\mathbf m_{ref}$ which is some first guess at the cell values of the area being inverted. The next three terms promote smoothness by penalizing large derivatives in the model, determined by the discrete gradient operator $\mathbf G$ in each direction. There are many parameters in $\phi_m$ that the geophysicist can use to fine-tune the recovered model. $\alpha_s$,$\alpha_x$,$\alpha_y$, and $\alpha_z$, scale the contribution of smallness and smoothness in each spatial direction. $\alpha$ values can be used to broadly determine the length scales in each direction of a recovered model. The $\mathbf w_s$,$\mathbf w_x$,$\mathbf w_y$,$\mathbf w_z$ parameters allow finer control. They weight the model's smallness and smoothness variable across its extent, allowing the user to specify certain regions as smoother than others or demanding that the recovered model more closely match the reference model in areas where the user is more certain of the reference model's validity. 

In \autoref{eq:phim} it is assumed the the norm of the regularization is $L_2$: 
\begin{equation}
\|\mathbf v\|_2 = \Big(\sum_{i=1}^N v_i^2\Big)^{\frac{1}{2}}.
\end{equation}
\label{eq:l2}
This formulation can be generalized to an $L_p$ norm that takes the form
\begin{equation}
\|\mathbf v\|_p = \Big(\sum_{i=1}^N |v_i|^p\Big)^{\frac{1}{p}}
\end{equation}
\label{eq:lp}
where $p$ is some positive number. Minimizing a objective function with a lower values of $p$ promote more sparsity in the vector $\mathbf v$.

The last term in Equation 1.3 is $\beta$ which determines the degree to which the model fits the data or obeys the regularization. Assuming that the error in $\mathbf d^{obs}$ is Gaussian  and  independent with the standard deviations in $\mathbf W_d$, $\phi_d$ will be a random variable with a $\chi^2$ distribution and an expected value of $N$, the number of data \cite{oldenburg2005inversion}. Given this expected value, beta can be iteratively decreased until the misfit is sufficiently near $N$.

%\autoref{eq:objectiveFunc}%
Having discussed the structure of regularized inversion I will now discuss previous research on including geological and petrophysical information in inversion using regularization.

\section{Literature Review}
\label{sec:Literature Review}

\subsection{Mathematical methods of constraining inversion resutls to a given shape}
\label{subsec:litrevMathMethods}

\subsubsection{Smoothly varying recovered models}
\label{subsubsec:smooth}
There has been much research following the lines of \cite{li19963} and \cite{li19983}. The methods used in these two papers are described in \autoref{sec:Regularized Inversion}. The advantage of using least-squares methods for the regularization of inverse problems is that the objective function is convex, continuous, and differentiable, which greatly aids the implementation of the optimization. Reference models and weighting matrices allow for the incorporation of geological information, making smallness and smoothness more or less significant in different parts of the model. \cite{li2003fast} extend the method by also implementing upper and lower bounds that can be specified for each model cell allowing the user to make hard constraints on the value of the model.

These methods recover smoothly varying models with broad distributions of the physical property. Sometimes the geological context indicates that the model should vary sharply and the anomalous body should be compact. In other words, either the model or its derivative should be sparse. There has been a great deal of research on using sparsity-promoting norms to achieve compact or sharply-varying models.

\subsubsection{Sharply varying recovered models (Blocky and Compact)}
\label{subsubsec:sharp}
Instead of regularizing by smallness and smoothness, \cite{last1983compact} regularize by compactness, essentially demanding that the anomaly be as small as possible while still fitting the data. They use an $L_0$ norm on the smallness component and do not use the smoothness constraints. \cite{portniaguine1999focusing} extend  \cite{last1983compact} by adding what they call a minimum gradient support functional. The effect of this support functional is a $L_0$ norm on the smoothness terms instead of the smallness term as in \cite{last1983compact}.

\cite{rudin1992nonlinear} and \cite{vogel1998fast} propose total variation methods in the context of de-noising and de-blurring images, in other words the use of $L_1$ norms to regularize, instead of $L_2$ norms as in \cite{li19963} and \cite{li19983}. Since minimizing $L_1$ norms promotes sparsity, regularizing by them will have a comparable effect (blocky models with sharp boundaries) as the method used by \cite{last1983compact} and \cite{portniaguine1999focusing}. Total variation has been used more specifically in the context of geophysical inversion, such as with \cite{guitton2012blocky}.	

\cite{farquharson1998non} also report ways of achieving sharp contrast by implementing non-$L_2$ norms such as Ekblom and Huber norms. \cite{fournier2015cooperative} implements a method of minimizing the general $L_p$ (smallness) and $L_q$ (smoothness) norms for any $p$ and $q$ (typically values between 0 and 2) allowing a user to specify the degree of compactness or blockiness of a recovered model in different spatial directions.

\subsubsection{Recovered models with dipping anomalies}
\label{subsubsec:dipping}

The formulation in \autoref{eq:phim} allows a great deal of control of the way the model varies along the three cardinal directions. However, the geometry of a deposit does not always align with any of the cardinal directions and diagonal structures are preferred. \cite{li2000incorporating}  extend the method of \cite{li19963} and \cite{li19983} by rotating the model objective function to allow for linear features in the recovered model to be in a direction not in line with the mesh grid. \cite{lelievre2009comprehensive} generalize the methods in \cite{li2000incorporating} to the 3D case.

\cite{guillen1984gravity} extend the method described in \cite{last1983compact}. Instead of minimizing the volume of a deposit, the authors minimize its moment of inertia. By specifying an axis of rotation to determine the moment of inertia, they put dip information into the regularization in addition to having the sharp contrasts and compact models as in \cite{last1983compact}.  \cite{barbosa1994generalized} and \cite{barbosa2006interactive} extend the method even further allowing multiple axes of rotation. The second paper also describes a GUI to interactively test the fit of various axes of rotation.

\cite{chasseriau20033d} create a very general method of biasing the inversion algorithm towards anomalies of almost any shape by weighting the smallness term with a covariance matrix of the model, i.e., a matrix with the covariance of each cell versus every other cell in the model. The covariance matrix can be generated from bore hole or surface sample data or from a synthetic initial model.

In addition to the deterministic inversions described above, much research has been done on stochastic inversion. \cite{bosch2001lithologic} directly invert for lithologies. The authors forward model physical properties by a probabilistic relation of the physical property to the lithology. New lithology distributions are created using a pseudo-random walk. \emph{A priori} information is included partially in the probabilistic model that links the lithology to the physical properties but also in the initial probability distribution of the lithology model. \cite{guillen2008geological} implement the method described in \cite{bosch2001lithologic} in 3D. 


Attempts have also been made at combining stochastic and deterministic methods. One particularly successful line of inquiry are \ac{FCM}. \cite{paasche2006integration} uses FCM clustering of recovered models to derive membership functions of model cells in several clusters. The clusters are then used with \emph{a priori} porosity data to create a likely porosity of each cluster and a porosity model is created from these results. 

Instead of clustering after an inversion to achieve the effect of a cooperative inversion like \cite{paasche2006integration}, \cite{sun2015multidomain} use the FCM function as an extra term in the model objective function. This allows them to simultaneously invert slowness and density (from travel time and gravity data) by linking them through the FCM clusters. It also allows them to guide the FCM cluster physical properties in a way that allows the integration of petrophysical measurements of geological units without directly forcing where the units are in space.

%For the purpose of this thesis I will use the framework described in \cite{li19963} and \cite{li19983}. This is partially due to computational efficiencies that come from deterministic inversion. It is also due to the fact the goal of this thesis is to integrate the creation of regularization with the actual inversion codes and data processing, as such I use the framework of the inversion software I am integrating with.

Finally, implementations of constrained inversions. \cite{phillips2001thesis} uses bore hole densities and susceptibilities to bound a gravity and a magnetic inversion need to be discussed. \cite{farquharson2008geologically} use density bore hole logs to create a reference model for a gravity inversion. They demonstrate the effect of having many bore holes versus only a few. \cite{williams2008geologically}  provides the most extensive review of this subject. He creates a software package to integrate a phenomenal number of types of geological and petrophysical data including bore hole, surface sample, geological shape files, and geological model both in the form of voxel models and 3D domain models. Many of the tools that he created are integrated into the work that I present. He then uses these tools to create detailed susceptibility and density constraints and applies them in inversions. Finally, \cite{Lelievre2009Integrating} discusses the use of surface samples and bore holes in constraining a synthetic example. He also shows the use of orientation information of linear features as a geological constraint. 

As stated in the research motivation, what is lacking in previous implementations is an integrated environment where data, models, inversions, and constraints can be developed. By implementing the creation of constraints in such an environment, I make the creation of constraints faster even in non-trivial contexts with multiple sources of information and multiple forms of constraints.

\section{Thesis Organization}
\label{sec:Thesis Organization}
		
In this thesis I describe the methods used to create the tools I contributed to GIFtools and give examples of their use. \autoref{ch:GIFtools} will discuss the tools I have created. It  describes the types of information that GIFtools and Model Builder can integrate into an inversion and discuss how they can be used to constrain an inversion result. I discuss how sample information (bore hole and surface sample data) can be used to set reference models and bounds. I also discuss geological maps and how Model Builder incorporates information from both cross section and plan view maps into the regularization of inversions. I also discuss parametric style inversions using a standard mesh and forward operator. Instead of allowing all cells to vary freely I constrain them to some number of units that must all be constant across the unit. Finally in \autoref{ch:GIFtools}  I discuss the use of clustering multiple inversion results to create non-trivial face weights in addition to reference models and bounds.

In \autoref{ch:CaseStudy1} I show the use of GIFtools and Model Builder in the creation of regularizations for a magnetic inversion in El Poma. El Poma is a porphyry deposit in Colombia that has magnetic properties measured from bore holes, surface samples, in addition to a geological map over the region. The region is also interesting due the large effect of remanent magnetization. I discuss a synthetic case, matching the magnetic survey, bore holes, surface samples and map to recover the anomaly. I also show the result of the inversion of the actual field data.

Finally in \autoref{ch:CaseStudy2} I show an example GIFtools and Model Builder in the context of the Tli Kwi Cho Kimberlite complex in the North West Territories, Canada. In this case there have been several surveys flown over the region for electromagnetic (of which I use only the magnetic data) and gravity gradiometry data. In addition to the geophysical data there has been extensive drilling, and cross section maps have been created. I show a synthetic example inverting both gravity gradiometry and magnetic data incorporating the \emph{a priori} information as well as using clustering of the magnetic and gravity inversion results to create further constraints.






%\section{Types of Data Included}
%\label{sec:Types of Data Included}

\endinput

Interestingly, the assumption that all magnetizations are in the same direction also assumes that all Koenigsberger ratios are equal.

Any text after an \endinput is ignored.
You could put scraps here or things in progress.
